{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCHIVED PORTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contingency_table = pd.crosstab(df[\"sender_domain\"], y_train[\"is_fraud_email\"])\n",
    "# chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# print(f\"Chi-Square Statistic: {chi2}\")\n",
    "# print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As p-value < 0.05, there is sufficient evidence to reject the null hypothesis and conclude that there is a statistically significant association between `sender_domain` and `is_fraud_email`. We will perform one-hot encoding for this variable so as to include it in subsequent analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# X_train_encoded = encoder.fit_transform(X_train[[\"sender_domain\"]])\n",
    "# X_test_encoded = encoder.transform(X_test[[\"sender_domain\"]])\n",
    "\n",
    "# # Convert the encoded arrays back to DataFrames for better readability (optional)\n",
    "# X_train_sender_domain_df = pd.DataFrame(\n",
    "#     X_train_encoded.toarray(), columns=encoder.get_feature_names_out()\n",
    "# )\n",
    "# X_test_sender_domain_df = pd.DataFrame(\n",
    "#     X_test_encoded.toarray(), columns=encoder.get_feature_names_out([\"sender_domain\"])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Email Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vectorizer = CountVectorizer()\n",
    "\n",
    "# X_train_bow = count_vectorizer.fit_transform(X_train[\"processed_lemmatized_text\"])\n",
    "# X_test_bow = count_vectorizer.transform(X_test[\"processed_lemmatized_text\"])\n",
    "\n",
    "# X_train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value 128273 illustrates the number of dimensions the bag of words contain. As the number if rather large, we will be reducing the number of features by removing low-variance features (i.e., words that hardly appear). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "# X_train_bow = selector.fit_transform(X_train_bow)\n",
    "# X_test_bow = selector.transform(X_test_bow)\n",
    "# feature_mask = selector.get_support()\n",
    "# feature_names = count_vectorizer.get_feature_names_out()\n",
    "# reduced_feature_names = feature_names[feature_mask]\n",
    "\n",
    "# X_train_bow_df = pd.DataFrame(X_train_bow.toarray(), columns=reduced_feature_names)\n",
    "# X_test_bow_df = pd.DataFrame(X_test_bow.toarray(), columns=reduced_feature_names)\n",
    "\n",
    "# X_train_bow_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_average_vector(words, model):\n",
    "#     word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "#     if not word_vectors:  # If no words are in the model's vocabulary\n",
    "#         return np.zeros(model.vector_size)\n",
    "#     return np.mean(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## Post Processing Data Visualisation\n",
    "# From the graphs above, we can see that there is a distinct difference in the distribution of `is_fraud_email` for `hour`, whereas the rest does not vary significantly in the distribution. Notably, there is a surge of emails in the year 2008, month of August and across the 5th to 8th of the month.\n",
    "# ## Feature Selection\n",
    "# X_train.info()\n",
    "# # following our analysis, we will be keeping:\n",
    "# #   body_contains_url, sender_domain (one-hot encoded), hour, body (the embedded text)\n",
    "# # dropped receiver_domain as anyone could receive fraudulent emails?\n",
    "# # TODO: Decide on what to do about subject\n",
    "# X_train = X_train[[\"body_contains_url\", \"hour\"]]\n",
    "# X_test = X_test[[\"body_contains_url\", \"hour\"]]\n",
    "\n",
    "# X_train = X_train.reset_index(drop=True)\n",
    "# X_train_sender_domain_df = X_train_sender_domain_df.reset_index(drop=True)\n",
    "# X_test = X_test.reset_index(drop=True)\n",
    "# X_test_sender_domain_df = X_test_sender_domain_df.reset_index(drop=True)\n",
    "\n",
    "# # concatenate one-hot encoded sender_domain\n",
    "# X_train = pd.concat([X_train, X_train_sender_domain_df], axis=1)\n",
    "# X_test = pd.concat([X_test, X_test_sender_domain_df], axis=1)\n",
    "# # concatenate body: bag of words\n",
    "# X_train_bow_df = X_train_bow_df.reset_index(drop=True)\n",
    "# X_test_bow_df = X_test_bow_df.reset_index(drop=True)\n",
    "\n",
    "# X_train_body_bow = pd.concat([X_train, X_train_bow_df], axis=1)\n",
    "# X_test_body_bow = pd.concat([X_test, X_test_bow_df], axis=1)\n",
    "# # concatenate body: tfidf\n",
    "# X_train_tfidf_df = X_train_tfidf_df.reset_index(drop=True)\n",
    "# X_test_tfidf_df = X_test_tfidf_df.reset_index(drop=True)\n",
    "\n",
    "# X_train_body_tfidf = pd.concat([X_train, X_train_tfidf_df], axis=1)\n",
    "# X_test_body_tfidf = pd.concat([X_test, X_test_tfidf_df], axis=1)\n",
    "# # concatenate body: word2vec\n",
    "# X_train_word2vec_df = X_train_word2vec_df.reset_index(drop=True)\n",
    "# X_test_word2vec_df = X_test_word2vec_df.reset_index(drop=True)\n",
    "\n",
    "# X_train_body_word2vec = pd.concat([X_train, X_train_word2vec_df], axis=1)\n",
    "# X_test_body_word2vec = pd.concat([X_test, X_test_word2vec_df], axis=1)\n",
    "# # concatenate body: sentence transformers\n",
    "# X_train_st_df = X_train_st_df.reset_index(drop=True)\n",
    "# X_test_st_df = X_test_st_df.reset_index(drop=True)\n",
    "\n",
    "# X_train_body_st = pd.concat([X_train, X_train_st_df], axis=1)\n",
    "# X_test_body_st = pd.concat([X_test, X_test_st_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_set(model_class, params=None):\n",
    "#     def run_model(X_train, X_test):\n",
    "#         model_params = params if params is not None else {}\n",
    "#         model = model_class(**model_params)  # Pass any necessary parameters here\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         report = classification_report(y_test, y_pred, output_dict=True)\n",
    "#         return (\n",
    "#             accuracy,\n",
    "#             report[\"Phishing Email\"][\"f1-score\"],\n",
    "#             report[\"Safe Email\"][\"f1-score\"],\n",
    "#         )\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     feature_sets = {\n",
    "#         \"Bag of Words\": (X_train_body_bow, X_test_body_bow),\n",
    "#         \"TF-IDF\": (X_train_body_tfidf, X_test_body_tfidf),\n",
    "#         \"Word2Vec\": (X_train_body_word2vec, X_test_body_word2vec),\n",
    "#         \"Sentence Transformer\": (X_train_body_st, X_test_body_st),\n",
    "#     }\n",
    "\n",
    "#     for feature_name, (X_train_feature, X_test_feature) in feature_sets.items():\n",
    "#         accuracy, spam_f1, non_spam_f1 = run_model(X_train_feature, X_test_feature)\n",
    "#         results.append(\n",
    "#             {\n",
    "#                 \"Feature Set\": feature_name,\n",
    "#                 \"Accuracy\": accuracy,\n",
    "#                 \"Phishing Email F1 Score\": spam_f1,\n",
    "#                 \"Safe Email F1 Score\": non_spam_f1,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#     return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models Individually (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the SVM classifier\n",
    "# svm_model = SVC(kernel='linear', random_state=1)\n",
    "\n",
    "# # Step 2: Train the SVM model\n",
    "# svm_model.fit(X_train_bow, y_train)\n",
    "\n",
    "# # Step 3: Make predictions on the test set\n",
    "# y_pred = svm_model.predict(X_test_bow)\n",
    "\n",
    "# # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the SVM classifier\n",
    "# svm_model = SVC(kernel='linear', random_state=1)\n",
    "\n",
    "# # Step 2: Train the SVM model\n",
    "# svm_model.fit(X_train_tfidf, y_train.values.ravel())  # Use ravel() to avoid issues with shape\n",
    "\n",
    "# # Step 3: Make predictions on the test set\n",
    "# y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Convert the lists of embeddings to numpy arrays\n",
    "# X_train_word2vec = np.array(X_train_word2vec_embedding.tolist())\n",
    "# X_test_word2vec = np.array(X_test_word2vec_embedding.tolist())\n",
    "\n",
    "# # Step 2: Initialize the SVM classifier\n",
    "# svm_model = SVC(kernel='linear', random_state=1)\n",
    "\n",
    "# # Step 3: Train the SVM model\n",
    "# svm_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# # Step 4: Make predictions on the test set\n",
    "# y_pred = svm_model.predict(X_test_word2vec)\n",
    "\n",
    "# # Step 7: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the SVM classifier\n",
    "# svm_model = SVC(kernel='linear', random_state=1)\n",
    "\n",
    "# # Step 2: Train the SVM model\n",
    "# svm_model.fit(train_embeddings, y_train.values.ravel())  # Use ravel() to avoid issues with shape\n",
    "\n",
    "# # Step 3: Make predictions on the test set\n",
    "# y_pred = svm_model.predict(test_embeddings)\n",
    "\n",
    "# # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_params = {\"random_state\": SEED}\n",
    "# svm = run_set(SVC, svc_params)\n",
    "# svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models Individually (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Train the Random Forest model\n",
    "# rf_model = RandomForestClassifier(random_state=1)  # You can adjust hyperparameters as needed\n",
    "# rf_model.fit(X_train_bow, y_train)\n",
    "\n",
    "# # Step 2: Make predictions\n",
    "# y_pred = rf_model.predict(X_test_bow)\n",
    "\n",
    "# # Step 3: Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Train the Random Forest model\n",
    "# rf_model = RandomForestClassifier(random_state=1)  # You can adjust hyperparameters as needed\n",
    "# rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Step 2: Make predictions\n",
    "# y_pred = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# # Step 3: Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Train the Random Forest model\n",
    "# rf_model = RandomForestClassifier(random_state=1)  # You can adjust hyperparameters as needed\n",
    "# rf_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# # Step 2: Make predictions\n",
    "# y_pred = rf_model.predict(X_test_word2vec)\n",
    "\n",
    "# # Step 3: Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Train the Random Forest model\n",
    "# rf_model = RandomForestClassifier(random_state=1)  # You can adjust hyperparameters as needed\n",
    "# rf_model.fit(train_embeddings, y_train)\n",
    "\n",
    "# # Step 2: Make predictions\n",
    "# y_pred = rf_model.predict(test_embeddings)\n",
    "\n",
    "# # Step 3: Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Step 1: Collect results\n",
    "# results = []\n",
    "\n",
    "\n",
    "# # Step 2: Define a function to train Random Forest and evaluate\n",
    "# def run_random_forest(X_train, X_test, y_train, y_test, feature_name):\n",
    "#     rf_model = RandomForestClassifier(\n",
    "#         random_state=1\n",
    "#     )  # You can adjust hyperparameters as needed\n",
    "#     rf_model.fit(X_train, y_train.values.ravel())\n",
    "#     y_pred = rf_model.predict(X_test)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     report = classification_report(y_test, y_pred, output_dict=True)\n",
    "#     return (\n",
    "#         accuracy,\n",
    "#         report[\"1\"][\"f1-score\"],\n",
    "#         report[\"0\"][\"f1-score\"],\n",
    "#     )  # Adjust 'Phishing Email'/'Safe Email' according to your labels\n",
    "\n",
    "\n",
    "# # Run Random Forest for each feature set\n",
    "# feature_sets = {\n",
    "#     \"Bag of Words\": (X_train_bow, X_test_bow),\n",
    "#     \"TF-IDF\": (X_train_tfidf, X_test_tfidf),\n",
    "#     \"Word2Vec\": (X_train_word2vec, X_test_word2vec),\n",
    "#     \"Sentence Transformer\": (train_embeddings, test_embeddings),\n",
    "# }\n",
    "\n",
    "# for feature_name, (X_train_feature, X_test_feature) in feature_sets.items():\n",
    "#     accuracy, phishing_f1, safe_f1 = run_random_forest(\n",
    "#         X_train_feature, X_test_feature, y_train, y_test, feature_name\n",
    "#     )\n",
    "#     results.append(\n",
    "#         {\n",
    "#             \"Feature Set\": feature_name,\n",
    "#             \"Accuracy\": accuracy,\n",
    "#             \"Phishing Email F1 Score\": phishing_f1,\n",
    "#             \"Safe Email F1 Score\": safe_f1,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# # Step 3: Create a DataFrame to represent the results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Step 4: Display the results\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models Individually (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the XGBoost classifier\n",
    "# xgb_model = XGBClassifier(\n",
    "#     use_label_encoder=True, eval_metric=\"mlogloss\", random_state=1\n",
    "# )\n",
    "\n",
    "# # Step 2: Train the model\n",
    "# xgb_model.fit(X_train_bow, y_train)\n",
    "\n",
    "# # # Step 3: Make predictions on the test set\n",
    "# y_pred = xgb_model.predict(X_test_bow)\n",
    "\n",
    "# # # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the XGBoost classifier\n",
    "# xgb_model = XGBClassifier(eval_metric=\"mlogloss\", random_state=1)\n",
    "\n",
    "# # Step 2: Train the model\n",
    "# xgb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # # Step 3: Make predictions on the test set\n",
    "# y_pred = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# # # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the XGBoost classifier\n",
    "# xgb_model = XGBClassifier(eval_metric=\"mlogloss\", random_state=1)\n",
    "\n",
    "# # Step 2: Train the model\n",
    "# xgb_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# # # Step 3: Make predictions on the test set\n",
    "# y_pred = xgb_model.predict(X_test_word2vec)\n",
    "\n",
    "# # # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Initialize the XGBoost classifier\n",
    "# xgb_model = XGBClassifier(eval_metric=\"mlogloss\", random_state=1)\n",
    "\n",
    "# # Step 2: Train the model\n",
    "# xgb_model.fit(train_embeddings, y_train)\n",
    "\n",
    "# # # Step 3: Make predictions on the test set\n",
    "# y_pred = xgb_model.predict(test_embeddings)\n",
    "\n",
    "# # # Step 4: Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Step 1: Collect results\n",
    "# results = []\n",
    "\n",
    "\n",
    "# # Step 2: Define a function to train XGBoost and evaluate\n",
    "# def run_xgboost(X_train, X_test, y_train, y_test, feature_name):\n",
    "#     xgb_model = XGBClassifier(eval_metric=\"mlogloss\", random_state=1)\n",
    "#     xgb_model.fit(X_train, y_train.values.ravel())\n",
    "#     y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     report = classification_report(y_test, y_pred, output_dict=True)\n",
    "#     return (\n",
    "#         accuracy,\n",
    "#         report[\"1\"][\"f1-score\"],\n",
    "#         report[\"0\"][\"f1-score\"],\n",
    "#     )  # Adjust 'Phishing Email'/'Safe Email' according to your labels\n",
    "\n",
    "\n",
    "# # Run XGBoost for each feature set\n",
    "# feature_sets = {\n",
    "#     \"Bag of Words\": (X_train_bow, X_test_bow),\n",
    "#     \"TF-IDF\": (X_train_tfidf, X_test_tfidf),\n",
    "#     \"Word2Vec\": (X_train_word2vec, X_test_word2vec),\n",
    "#     \"Sentence Transformer\": (train_embeddings, test_embeddings),\n",
    "# }\n",
    "\n",
    "# for feature_name, (X_train_feature, X_test_feature) in feature_sets.items():\n",
    "#     accuracy, phishing_f1, safe_f1 = run_xgboost(\n",
    "#         X_train_feature, X_test_feature, y_train, y_test, feature_name\n",
    "#     )\n",
    "#     results.append(\n",
    "#         {\n",
    "#             \"Feature Set\": feature_name,\n",
    "#             \"Accuracy\": accuracy,\n",
    "#             \"Phishing Email F1 Score\": phishing_f1,\n",
    "#             \"Safe Email F1 Score\": safe_f1,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# # Step 3: Create a DataFrame to represent the results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Step 4: Display the results\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
